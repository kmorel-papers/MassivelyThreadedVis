%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for kmorel at 2013-09-04 16:51:26 -0600 


%% Saved with string encoding Unicode (UTF-8) 



@techreport{CGNS,
	Annote = {CFD General Notation System (CGNS) is an industry standard for representing topologies.},
	Author = {Christopher L. Rumsey and Diane M. A. Poirier and Robert H. Bush and Charles E. Towne},
	Date-Added = {2013-09-04 22:51:23 +0000},
	Date-Modified = {2013-09-04 22:51:23 +0000},
	Institution = {NASA},
	Month = {October},
	Number = {TM-2001-211236},
	Title = {A User's Guide to CGNS},
	Year = {2001}}

@inproceedings{Levy2001,
	Abstract = {We present the Circular Incident Edge Lists (CIEL), a new data structure and a high-performance algorithm for generating a series of iso-surfaces in a highly unstructured grid. Slicing-based volume rendering is also considered. The CIEL data structure represents all the combinatorial information of the grid, making it possible to optimize the classical propagation from local minima paradigm. The usual geometric structures are replaced by a more efficient combinatorial structure. An active edges list is maintained, and iteratively propagated from an iso-surface to the next one in a very efficient way. The intersected cells incident to each active edge are retrieved, and the intersection polygons are generated by circulating around their facets. This latter feature enables arbitrary irregular cells to be treated, such as those encountered in certain computational fluid dynamics (CFD) simulations. Since the CIEL data structure solely depends on the connections between the cells, it is possible to take into account dynamic changes in the geometry of the mesh and in property values, which only requires the sorted extrema list to be updated. Experiments have shown that our approach is significantly faster than classical methods. The major drawback of our method is its memory consumption, higher than most classical methods. However, experimental results show that it stays within a practical range.},
	Annote = {Describes circular incident edge lists (CIEL) to represent polyhedral meshes. Circular incident edge lists are represented almost wholly by half edges. Each half-edge belongs to a particular face of a particular cell. Each half-edge has several links to capture the polyhedra topology:* A link to the next vertex in the face of the cell (equivalent to the adjacent edge link in a half-edge data structure).* A link to the half edge of the adjacent face in the same cell (equivalent to the adjacent polygon in a half-edge data structure).* A link to the corresponding half-edge in the adjacent cell along the face (which will be pointing in the opposite direction).* A linked list of all half-edges attached to a vertex.},
	Author = {Bruno L\'{e}vy and Guillaume Caumon and St\'{e}phane Conreaux and Xavier Cavin},
	Booktitle = {Proceedings of IEEE Visualization},
	Date-Added = {2013-09-04 22:44:31 +0000},
	Date-Modified = {2013-09-04 22:44:31 +0000},
	Month = {October},
	Pages = {191--198},
	Title = {Circular Incident Edge Lists: a Data Structure for Rendering Complex Unstructured Grids},
	Year = {2001}}

@inproceedings{Kettner1998,
	Abstract = {Design solutions for a program library are presented for combinato- 
rial data structures in computational geometry, such as planar maps 
and polyhedral surfaces. Design issues considered are genericity, 
flcsibility, time and space efficiency, and ease-of-use. We focus 
on topological aspects of polyhedral surfaces. Edge-based repre- 
w%ations for polyhedrons are evaluated with respect to the design 
goals. A design for polyhedral surfaces in a halfedge data structure 
is developed following the generic programming paradigm known 
from the Standard Template Library STL for C++. Connections 
arc shown to planar maps and face-based structures managing holes 
in facets.},
	Annote = {Describes half-edge structures for representing polygonal meshes. In a conformal polygon mesh, each edge is shared by (at most) two polygons. In the half-edge structure, each edge is represented by two half edges, each associated with one of the two adjacent polygons. A polygon is represented as the cycle of half edges around it. Each half-edge points to the next half edge and the adjacent half edge, which is pointing in the opposite direction.},
	Author = {Lutz Kettner},
	Booktitle = {Proceedings of the Fourteenth ACM Symposium on Computational Geometry},
	Date-Added = {2013-09-04 22:31:21 +0000},
	Date-Modified = {2013-09-04 22:31:21 +0000},
	Note = {{DOI}~10.1145/276884.276901},
	Pages = {146--154},
	Title = {Designing a Data Structure for Polyhedral Surfaces},
	Year = {1998}}

@inproceedings{Alumbaugh2005,
	Abstract = {In this paper, we present simple and efficient array-based mesh data structures, including a compact representation of the half-edge data structure for surface meshes, and its generalization --a half-face data structure-- for volume meshes. These array-based structures provide comprehensive and efficient support for querying incidence, adjacency, and boundary classification, but require substantially less memory than pointer-based mesh representations. In addition, they are easy to implement in traditional programming languages (such as in C or Fortran 90) and convenient to exchange across different software packages or different storage media. In a parallel setting, they also support partitioned meshes and hence are particularly appealing for large-scale scientific and engineering applications. We demonstrate the construction and usage of these data structures for various operations, and compare their space and time complexities with alternative structures.},
	Annote = {Describes a cellular data structure (sometimes abbreviated CDS). It is based on the observation that each polyhedron in a linear mesh is itself a manifold polygon mesh. Thus, each polyhedron is represented with a half-edge structure. The global mesh topology is represented by half-faces (also sometimes called half-facets). Each cell has a circular linked list of half-faces. As the name implies, there are two half-faces for each face in the mesh, one for each incident cell. Each half-face points to the next half-face in the cell's list, the half-face for the adjacent cell, and a half edge for the face in the half-edge structure for this cell.},
	Author = {Tyler J Alumbaugh and Xiangmin Jiao},
	Booktitle = {Proceedings, 14th International Meshing Roundtable},
	Date-Added = {2013-09-04 22:23:32 +0000},
	Date-Modified = {2013-09-04 22:23:32 +0000},
	Month = {September},
	Pages = {485--504},
	Title = {Compact Array-Based Mesh Data Structures},
	Year = {2005}}

@misc{Bell2010,
	Annote = {A presentation containing several example programs in thrust.  One important one for us (and does not have a lot of other examples) is an implementation of vertex-weld.},
	Author = {Bell, Nathan},
	Booktitle = {GPU Technology Conference},
	Date-Added = {2013-09-04 20:02:08 +0000},
	Date-Modified = {2013-09-04 20:02:08 +0000},
	File = {:home/bob/Desktop/Old Ubuntu FS/home/bob/Papers/GPUCoincidentPoints/References/GTC 2010 (Part 1) - High Productivity Development.pdf:pdf},
	Title = {High-Productivity {CUDA} Development with the Thrust Template Library},
	Year = {2010}}

@book{VTKUsersGuide,
	Annote = {User's guide for VTK.},
	Author = {Kitware Inc.},
	Date-Added = {2013-09-04 19:58:43 +0000},
	Date-Modified = {2013-09-04 19:58:43 +0000},
	Edition = {11th},
	Note = {{ISBN} 978-1-930934-23-8},
	Publisher = {Kitware Inc.},
	Title = {The VTK User's Guide},
	Year = {2010}}

@book{VTK,
	Annote = {Dude, it's VTK.},
	Author = {Will Schroeder and Ken Martin and Bill Lorensen},
	Date-Added = {2013-09-04 19:54:49 +0000},
	Date-Modified = {2013-09-04 19:54:49 +0000},
	Edition = {Fourth},
	Note = {{ISBN} 1-930934-19-X},
	Publisher = {Kitware Inc.},
	Title = {The Visualization Toolkit: An Object Oriented Approach to {3D} Graphics},
	Year = {2004}}

@article{Childs2013,
	Abstract = {As the visualization research community reorients its software to address up-coming challenges, it must successfully deal with diverse processor architectures, distributed systems, various data sources, massive parallelism, multiple input and output devices, and interactivity.
},
	Annote = {This article gives a high level overview of the challenges of large-scale HPC visualization in the exascale/extreme scale from a technical standpoint.  The issues raised are: Massive Parallelization, Processor Architectures and Programming Models, Application Architecture and Data Management, Data Models, Rendering, and Interaction.},
	Author = {Hank Childs and Berk Geveci and Will Schroeder and Jeremy Meredith and Kenneth Moreland and Christopher Sewell and Torsten Kuhlen and E. Wes Bethel},
	Date-Added = {2013-09-04 15:38:35 +0000},
	Date-Modified = {2013-09-04 15:38:35 +0000},
	Journal = {IEEE Computer},
	Month = {May},
	Note = {{DOI}~10.1109/MC.2013.179},
	Number = {5},
	Pages = {34--42},
	Title = {Research Challenges for Visualization Software},
	Volume = {46},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/MC.2013.179}}

@inproceedings{Meredith2012,
	Abstract = {Analysis and visualization of the data generated by scientific simulation codes is a key step in enabling science from computation. However, a number of challenges lie along the current hardware and software paths to scientific discovery. First, only advanced parallelism techniques can take full advantage of the unprecedented scale of coming machines. In addition, as computational improvements outpace those of I/O, more data will be discarded and I/O-heavy analysis will suffer. Furthermore, the limited memory environment, particularly in the context of in situ analysis which can sidestep some I/O limitations, will require efficiency of both algorithms and infrastructure. Finally, advanced simulation codes with complex data models require commensurate data models in analysis tools. However, community visualization and analysis tools designed for parallelism and large data fall short in a number of these areas. In this paper, we describe EAVL, a new library with infrastructure and algorithms designed to address these critical needs for current and future generations of scientific software and hardware. We show results from EAVL demonstrating the strengths of its robust data model, advanced parallelism, and efficiency.},
	Annote = {Another EAVL paper with a bit more technical content than the GPGPU-5 reference. Talks a bit more about how the data model works and provides more examples.

Specifically talkes about dimentionality reduction, high order interpolation, scalar warp (called elevation in the paper) and threshold using advanced structures.
},
	Author = {Jeremy S. Meredith and Sean Ahern and Dave Pugmire and Robert Sisneros},
	Booktitle = {Eurographics Symposium on Parallel Graphics and Visualization (EGPGV)},
	Date-Added = {2013-09-03 23:39:47 +0000},
	Date-Modified = {2013-09-03 23:39:47 +0000},
	Note = {{DOI}~10.2312/EGPGV/EGPGV12/021-030},
	Pages = {21--30},
	Title = {{EAVL}: The Extreme-scale Analysis and Visualization Library},
	Year = {2012}}

@inproceedings{Maynard2013,
	Abstract = {As the HPC community starts focusing its efforts towards exascale, it becomes clear that we are looking at machines with a billion way concurrency. Although parallel computing has been at the core of the performance gains achieved until now, scaling over 1,000 times the current concurrency can be challenging. As discussed in this paper, even the smallest memory access and synchronization overheads can cause major bottlenecks at this scale. As we develop new software and adapt existing algorithms for exascale, we need to be cognizant of such pitfalls. In this paper, we document our experience with optimizing a fairly common and parallelizable visualization algorithm, threshold of cells based on scalar values, for such highly concurrent architectures. Our experiments help us identify design patterns that can be generalized for other visualization algorithms as well. We discuss our implementation within the Dax toolkit, which is a framework for data analysis and visualization at extreme scale. The Dax toolkit employs the patterns discussed here within the framework's scaffolding to make it easier for algorithm developers to write algorithms without having to worry about such scaling issues.},
	Annote = {A reporting on some of the optimizations we did for threshold in Dax.},
	Author = {Robert Maynard and Kenneth Moreland and Utkarsh Ayachit and Berk Geveci and Kwan-Liu Ma},
	Booktitle = {Visualization and Data Analysis 2013, Proceedings of SPIE-IS\&T Electronic Imaging},
	Date-Added = {2013-09-03 23:23:47 +0000},
	Date-Modified = {2013-09-03 23:23:47 +0000},
	Month = {February},
	Title = {Optimizing Threshold for Extreme Scale Analysis},
	Year = {2013}}

@techreport{PISTON,
	Abstract = {Due to the wide variety of current and next-generation supercomputing architectures, the development of highperformance parallel visualization and analysis operators frequently requires re-writing the underlying algorithms for many different platforms. In order to facilitate portability, we have devised a framework for creating such operators that employs the data-parallel programming model. By writing the operators using only data-parallel primitives (such as scans, transforms, stream compactions, etc.), the same code may be compiled to multiple targets using architecture-specific backend implementations of these primitives. Specifically, we make use of and extend NVIDIA's Thrust library, which provides CUDA and OpenMP backends. Using this framework, we have implemented isosurface, cut surface, and threshold operators, and have achieved good parallel performance on two different architectures (multi-core CPUs and NVIDIA GPUs) using the exact same operator code. We have applied these operators to several large, real scientific data sets, and have open-source released a beta version of our code base.},
	Annote = {A library providing portable implementations of visualization algorithms on multi- and many-core processors.  Uses Thrust to implement algorithms and portability.  Compares marching cubes isosurface generation to existing implementations by NVIDIA and VTK.

I believe this was presented at EGPGV 2012 and when it becomes available in the proceedings this reference should be updated.
},
	Author = {Li-Ta Lo and Chris Sewell and James Ahrens},
	Date-Added = {2013-09-03 23:18:03 +0000},
	Date-Modified = {2013-09-03 23:18:03 +0000},
	Institution = {Los Alamos National Laboratory},
	Number = {LA-UR-12-10227},
	Title = {{PISTON}: A Portable Cross-Platform Framework for Data-Parallel Visualization Operators},
	Year = {2012},
	Bdsk-Url-1 = {http://viz.lanl.gov/projects/PISTON.html}}

@inproceedings{Sewell2012,
	Abstract = {This paper surveys the four software frameworks being developed as part of the visualization pillar of the SDAV (Scalable Data Management, Analysis, and Visualization) Institute, one of the SciDAC (Scientific Discovery through Advanced Computing) Institutes established by the ASCR (Advanced Scientific Computing Research) Program of the U.S. Department of Energy. These frameworks include EAVL (Extreme-scale Analysis and Visualization Library), DAX (Data Analysis at Extreme), DIY (Do It Yourself), and PISTON. The objective of these frameworks is to facilitate the adaptation of visualization and analysis algorithms to take advantage of the available parallelism in emerging multi-core and many-core hardware architectures, in anticipation of the need for such algorithms to be run in-situ with LCF (leadership-class facilities) simulation codes on supercomputers.},
	Annote = {Describes four frameworks addressing large-scale HPC visualization problems.  These are EAVL, Dax, DIY, and PISTON.
},
	Author = {Christopher Sewell and Jeremy Meredith and Kenneth Moreland and Tom Peterka and Dave DeMarle and Li-ta Lo and James Ahrens and Robert Maynard and Berk Geveci},
	Booktitle = {2012 SC Companion (Proceedings of the Ultrascale Visualization Workshop)},
	Date-Added = {2013-09-03 23:17:47 +0000},
	Date-Modified = {2013-09-03 23:17:47 +0000},
	Month = {November},
	Note = {{DOI}~10.1109/SC.Companion.2012.36},
	Pages = {206--214},
	Title = {The {SDAV} Software Frameworks for Visualization and Analysis on Next-Generation Multi-Core and Many-Core Architectures},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SC.Companion.2012.36}}

@inproceedings{Moreland2011:LDAV,
	Annote = {Description of the Dax toolkit, a framework for building algorithms for GPU computers and, later, exascale computers.},
	Author = {Kenneth Moreland and Utkarsh Ayachit and Berk Geveci and Kwan-Liu Ma},
	Booktitle = {Proceedings of the IEEE Symposium on Large-Scale Data Analysis and Visualization},
	Date-Added = {2013-09-03 22:44:03 +0000},
	Date-Modified = {2013-09-03 22:44:03 +0000},
	Month = {October},
	Note = {{DOI}~10.1109/LDAV.2011.6092323},
	Pages = {97--104},
	Title = {Dax Toolkit: A Proposed Framework for Data Analysis and Visualization at Extreme Scale},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LDAV.2011.6092323}}

@inproceedings{EAVL,
	Abstract = {The coming generation of supercomputing architectures will require fundamental changes in programming models to effectively make use of the expected million to billion way concurrency and thousand-fold reduction in per-core memory. Most current parallel analysis and visualization tools achieve scalability by partitioning the data, either spatially or temporally, and running serial computational kernels on each data partition, using message passing as needed. These techniques lack the necessary level of data parallelism to execute effectively on the underlying hardware. This paper introduces a framework that enables the expression of analysis and visualization algorithms with memory-efficient execution in a hybrid distributed and data parallel manner on both multi-core and many-core processors. We demonstrate results on scientific data using CPUs and GPUs in scalable heterogeneous systems.},
	Annote = {Provides an overview of EAVL, mult-core, many-core, GPU, exascale thinking system.  EAVL defines operations with the use of functors.  Current operations look limited to basic mapping operations that can look at topological connections.  The really unique thing about EAVL is its data model that can adapt to many topological features and can handle things like edge and face data.  It also seems like it can map pretty easily to these features.},
	Author = {Jeremy S. Meredith and Robert Sisneros and David Pugmire and Sean Ahern},
	Booktitle = {Proceedings of the 5th Annual Workshop on General Purpose Processing with Graphics Processing Units (GPGPU-5)},
	Date-Added = {2013-09-03 22:41:45 +0000},
	Date-Modified = {2013-09-03 22:41:45 +0000},
	Month = {March},
	Note = {{DOI}~10.1145/2159430.2159432},
	Pages = {11--19},
	Title = {A Distributed Data-Parallel Framework for Analysis and Visualization Algorithm Development},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2159430.2159432}}

@book{Quinn2004,
	Annote = {A book containing mostly practical algorithms and their implementations using MPI and OpenMP.  The book also contains what I think is a nice review of some of the basic theory of parallel computing including Amdahl's law, Gustafson-Barsis's law, the Karp-Flatt metric, and the Isoefficiency metric.},
	Author = {Michael J. Quinn},
	Date-Added = {2013-09-03 21:31:50 +0000},
	Date-Modified = {2013-09-03 21:31:50 +0000},
	Note = {{ISBN}~978-0-07-282256-4},
	Publisher = {McGraw-Hill},
	Title = {Parallel Programming in C with MPI and OpenMP},
	Year = {2004}}

@book{TBB,
	Annote = {The user's guide and reference book for Intel Threading Building Blocks (TBB).  Also contains lots of practical advice on creating efficient application including notes on locking, allocations, cache-lines, and false-sharing.},
	Author = {James Reinders},
	Date-Added = {2013-09-03 21:29:31 +0000},
	Date-Modified = {2013-09-03 21:29:31 +0000},
	Month = {July},
	Note = {{ISBN}~978-0-596-51480-8},
	Publisher = {O'Reilly},
	Title = {Intel Threading Building Blocks: Outfitting {C++} for Multi-core Processor Parallelism},
	Year = {2007}}

@inbook{Thrust,
	Annote = {A portable STL-like template library for use on multi- and many-core systems.},
	Author = {Nathan Bell and Jared Hoberock},
	Chapter = {Thrust: A Productivity-Oriented Library for {CUDA}},
	Date-Added = {2013-09-03 21:29:13 +0000},
	Date-Modified = {2013-09-03 21:29:13 +0000},
	Month = {October},
	Pages = {359--371},
	Publisher = {Morgan Kaufmann},
	Title = {GPU Computing Gems, Jade Edition},
	Year = {2011}}

@book{Sanders2011,
	Annote = {A book describing how to use CUDA including a lot of practical advice.},
	Author = {Jason Sanders and Edward Kandrot},
	Date-Added = {2013-09-03 21:28:53 +0000},
	Date-Modified = {2013-09-03 21:28:53 +0000},
	Note = {{ISBN}~978-0-13-138768-3},
	Publisher = {Addison Wesley},
	Title = {{CUDA} by Example},
	Year = {2011}}

@inproceedings{Baker2010,
	Abstract = {Multicore nodes have become ubiquitous in just a few years. At the same time, writing portable parallel software for multicore nodes is extremely challenging. Widely available programming models such as OpenMP and Pthreads are not useful for devices such as graphics cards, and more flexible programming models such as RapidMind are only available commercially. OpenCL represents the first truly portable standard, but its availability is limited. In the presence of such transition, we have developed a minimal application programming interface (API) for multicore nodes that allows us to write portable parallel linear algebra software that can use any of the aforementioned programming models and any future standard models. We utilize C++ template meta-programming to enable users to write parallel kernels that can be executed on a variety of node types, including Cell, GPUs and multicore CPUs. The support for a parallel node is provided by implementing a Node object, according to the requirements specified by the API. This ability to provide custom support for particular node types gives developers a level of control not allowed by the current slate of proprietary parallel programming APIs. We demonstrate implementations of the API for a simple vector dot-product on sequential CPU, multicore CPU and GPU nodes.},
	Annote = {This is a paper from Mike Heroux and gang about the multi-core parallel technique using functors.  It makes for a vary portable system parallel system and this is demonstrated on intel threaded building blocks (TBB) and CUDA.},
	Author = {Christopher G. Baker and Michael A. Heroux and H. Carter Edwards and Alan B. Williams},
	Booktitle = {Proceedings of the 18th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
	Date-Added = {2013-09-03 20:54:28 +0000},
	Date-Modified = {2013-09-04 16:04:40 +0000},
	Month = {February},
	Note = {{DOI}~10.1109/PDP.2010.49},
	Pages = {601--606},
	Title = {A Light-weight {API} for Portable Multicore Programming},
	Year = {2010},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5452412},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/PDP.2010.49}}

@article{Lorensen1987,
	Annote = {The seminal work on the marching cubes algorithm for contour/isosurface.},
	Author = {William E. Lorensen and Harvey E. Cline},
	Date-Added = {2013-08-30 15:08:16 -0600},
	Date-Modified = {2013-08-30 15:08:16 -0600},
	Journal = {Computer Graphics (Proceedings of SIGGRAPH 87)},
	Month = {July},
	Number = {4},
	Pages = {163--169},
	Title = {Marching Cubes: A High Resolution {3D} Surface Construction Algorithm},
	Volume = {21},
	Year = {1987}}

@article{Ahrens2001,
	Annote = {One of the seminal papers on introducing parallelism and data streaming into VTK specifically and into pipelines in general.  Talks significantly about ghost cells and requirements for algorithms to work well in streaming.  Less talk about data parallelism.},
	Author = {James Ahrens and Kristi Brislawn and Ken Martin and Berk Geveci and C. Charles Law and Michael Papka},
	Date-Added = {2013-08-29 22:31:41 +0000},
	Date-Modified = {2013-08-29 22:31:41 +0000},
	Journal = {IEEE Computer Graphics and Applications},
	Month = {July/August},
	Number = {4},
	Pages = {34--41},
	Title = {Large-Scale Data Visualization Using Parallel Data Streaming},
	Volume = {21},
	Year = {2001}}

@inproceedings{Law1999,
	Annote = {Describes out-of-core streaming in VTK/visualization pipelines.  Also describes the properties an algorithm must have to enable streaming: separable, result invariant, and mappable.},
	Author = {C. Charles Law and Kenneth M. Martin and William J. Schroeder and Joshua Temkin},
	Booktitle = {Proceedings of IEEE Visualization 1999},
	Date-Added = {2013-08-29 22:31:35 +0000},
	Date-Modified = {2013-08-29 22:31:35 +0000},
	Month = {October},
	Pages = {225--232},
	Title = {A Multi-Threaded Streaming Pipeline Architecture for Large Structured Data Sets},
	Year = {1999}}

@article{Sutter2005,
	Annote = {A well cited article describing the trend of processors from faster cores every generation to more threads every generation. Argues that the "free lunch" of algorithms working better over time because processors get faster is over. The predictions of the article have generally been shown to be right.},
	Author = {Herb Sutter},
	Date-Added = {2013-08-28 22:33:53 +0000},
	Date-Modified = {2013-08-28 22:33:53 +0000},
	Journal = {Dr. Dobb's Journal},
	Number = {3},
	Title = {The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software},
	Volume = {30},
	Year = {2005}}

@book{ParaView,
	Annote = {Dude, its ParaView.},
	Author = {Utkarsh Ayachit and others},
	Date-Added = {2013-08-27 23:19:50 +0000},
	Date-Modified = {2013-08-27 23:19:50 +0000},
	Edition = {4th},
	Note = {{ISBN} 978-1-930934-24-5},
	Publisher = {Kitware Inc.},
	Title = {The {ParaView} Guide: A Parallel Visualization Application},
	Year = {2012},
	Bdsk-Url-1 = {http://www.paraview.org}}
