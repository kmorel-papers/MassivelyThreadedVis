% -*- latex -*-

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This metadata is specific for the sig-alternate document class.

\documentclass{sig-alternate}

\conferenceinfo{Ultravis}{2013 Denver, CO USA}
\CopyrightYear{2013} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.

\title{A Classification of Scientific Visualization Algorithms for Massive Threading}

% ACM has this complicated setup for authors that only really works for 6
% or less and is pretty big and pretty ugly in any case. This is amore
% compact representation.

\numberofauthors{1}

\author{
  \alignauthor
  Kenneth~Moreland,$^{\ddagger}$ Berk~Geveci,$^*$ Kwan-Liu~Ma,$^{\dagger}$ ...\\
  \affaddr{$^{\ddagger}$Sandia National Laboratories}\\
  \affaddr{$^*$Kitware, Inc.}\\
  \affaddr{$^{\dagger}$University of California at Davis}\\
}

% End of metadata specific for sig-alternate document class.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{varioref}
\usepackage{fancyvrb}
\usepackage{ifthen}
\usepackage{cite}
\usepackage{subfig}
\usepackage{xspace}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage{verbatim}

\usepackage{color}
\definecolor{yellow}{rgb}{1,1,0}
\definecolor{black}{rgb}{0,0,0}
\definecolor{ltcyan}{rgb}{.75,1,1}
\definecolor{red}{rgb}{1,0,0}
\definecolor{gray}{rgb}{.6,.6,.6}
\definecolor{darkred}{rgb}{0.5,0,0}
\definecolor{darkgreen}{rgb}{0,0.5,0}

% Cite commands I use to abstract away the different ways to reference an
% entry in the bibliography (superscripts, numbers, dates, or author
% abbreviations).  \scite is a short cite that is used immediately after
% when the authors are mentioned.  \lcite is a full citation that is used
% anywhere.  Both should be used right next to the text being cited without
% any spacing.
\newcommand*{\lcite}[1]{~\cite{#1}}
\newcommand*{\scite}[1]{~\cite{#1}}

\newcommand{\etal}{et al.}

\newcommand*{\keyterm}[1]{\emph{#1}}

\newcommand{\fix}[1]{{\color{red}\textsc{[#1]}}}

% Avoid putting figures on their own page.
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.95}
\renewcommand{\bottomfraction}{0.95}

% Make sure this is big enough so that only big figures end up on their own
% page but small enough so that if a figure does have to be on its own
% page, it won't push everything to the bottom because it's not big enough
% to have its own page.
\renewcommand{\floatpagefraction}{.75}

\newenvironment{packed_itemize}{
  \begin{itemize}[noitemsep]
}{
  \end{itemize}
}

\newcommand{\algorithmclasssection}[1]{\paragraph{#1}}

\newcommand{\algorithmclass}[5]{
  \algorithmclasssection{#1} %
  \begin{description}[leftmargin=4.5em,style=nextline,noitemsep]
  \item[Input] #2
  \item[Output] #3
  \item[Overlap] #4
  \item[Algorithms] #5
  \end{description}
}

\hyphenation{Para-View Map-Re-duce}

\begin{document}

\maketitle

\begin{abstract}

As the number of cores in processors increase and accelerator architectures
are becoming more common, an ever greater number of threads is required to
achieve full processor utilization. Our current parallel scientific
visualization codes rely on a partitioning of data to achieve parallel
processing, but this approach will not scale as we approach massive
threading in which work is distributed in such a fine level that each
thread is responsible for a minute portion of data. In this paper we
characterize the challenges of refactoring our current visualization
algorithms by considering the finest portion of work each performs and
examining the domain of input data, overlaps of output domains, and
interdependencies among work instances. \fix{Some further sentence about
  number of classes and how it will help focus research.}

\end{abstract}

\section{Introduction}

\noindent
Processor clock and execution rates have flatlined. Instead, successive
generations of processors provide more parallel threading
capability\lcite{Sutter2005}. Recent CPUs feature multiple cores and
hyperthreading technology to allow each core to run concurrent
threads. Furthermore, accelerator type architectures, which have
lightweight cores grouped to share control, are becoming increasingly
popular for their high price and power to performance ratios.

High performance computing is also seeing a remarkable increase in the
parallelism required on large-scale systems. Consider, for example, the
last two generations of leadership-class computers at the Oak Ridge
Leadership Computing Facility. The previous Jaguar-XT5 system had a peak
performance of about 2 petaflops using about 200 thousand concurrent
processes. The current Titan-XK7 system, which incoporates GPU
accelerators, has a peak performance of over 20 petaflops but can require
70 to 500 \emph{million} concurrent threads in order to achieve that.

Production visualization products today achieve parallel scalability using
a data parallel method that relies on partitioning the data into
independent domains for each process\lcite{Ahrens2001}. Each domain is
processed independently, so ghost regions and overlap are required at
domain boundaries so that the interaction of work on parallel processes can
be ignored. However, this approach is infeasible when dealing with massive
amounts of threads on these emerging architectures. We now need to design
new algorithms with a key on data interdependencies to process efficiently
in these massively multithreaded environment.

Unfortunately, to perform scientific visualization with massive threading,
we need to redesign our algorithms to work effectively with fine-grained,
independent operations. There has already been significant work in making
scientific visualization algorithms work well with shared memory threading
and accelerator types of architectures\fix{cite,cite,cite}, but all these
projects focus on the implementation of a single or select fixed set of
algorithms. Our goal in this paper is to present commonalities among
various algorithms that share parallel-programming challenges. By
addressing this higher level challenges, we can make better progress to
ensure that our scalable scientific visualization needs are met.

To identify these high level parallel-programming challenges, we first
revisit the key principles on which we base our current parallel
visualization algorithms (Section~\ref{sec:KeyPrinciples}) and then
categorize our current set of scientific visualization algorithms based on
behavior of the fundamental computation
(Section~\ref{sec:Classification}).


\section{Key Principles}
\label{sec:KeyPrinciples}

\noindent
Our current scalable scientific visualization relies on a coarse
partitioning of data into domains that can often be processed
independently. Law \etal\scite{Law1999} provides the following three key
principles that must be satisfied for this independent processing to behave
correctly.

\begin{description}
\item[Data Separability] The data can be broken into domains in a way that
  is simple and efficient. Furthermore, algorithms behave properly on
  independent domains.
\item[Mappable Input] Given an identification for a portion of the output,
  the input domain responsible for this output can be determined. The
  output portion can, and often is, identified as simple piece $i$ of $N$.
\item[Result Invariant] The output of the algorithm is equivalent across
  all possible partitioning.
\end{description}

At first glance, it would appear that any algorithm abiding these key
principles could be partitioned indefinitely. However, there are two
problems that arise when building a massively threaded algorithm in which
the data is partitioned (potentially) down to domains of single elements.

The first problem is that many algorithms do not really have a clear
mapping from an algorithm's output to its input. For example, when
computing a contour\lcite{Lorensen1987}, it is seldom practical to know a
priori how large the output will be, from what domain of the input each
piece of the output will originate, and what the distribution of elements
in the output partitions will be. As long as the data partitioning is
coarse enough, managing uneven or even empty domains is
inconsequential. Load imbalance in downstream processing can either be
resolved by dynamic rebalancing or, more commonly, simply tolerating
it. However, to achieve efficency with massive threading, it is important
to know the precise elements on which to schedule the working
threads. Thus, it is often more practical to determine partitioning by
mapping from input to output rather than output to input.

The second problem is that although plenty of algorithms are result
invariant in that different partitioning results in \emph{equivalent}, the
structures they build are not strictly \emph{isomorphic}. Partitioning data
often results in duplicate information on domain boundaries. \fix{Add
  figure and description demonstrating duplicated points when slice is
  partitioned.}

This duplication of results is a convenient mechanism to avoid
communication in parallel processing, and in coarse-level parallelism the
duplication is easily managed through ghost regions. However, if massive
threading reduces each domain to every independent element, the duplication
is dramatic and creating ghost regions is infeasible. It is therefore not
practical to assume result invariance for most algorithms. Instead we have
to identify and characterize the \keyterm{overlap} of the work occuring on
independent threads and design strategies to manage the work
overlap. \fix{This is a pretty weak definition.}

With these issues in mind, we provide an analogous set of key principles
for the operation of scientific visualization algorithms for massive
threading.

\begin{description}
\item[Data Separability] The data can be broken down to an elemental level
  fine enough to provide independent work for sufficient threads.
\item[Discoverable Input Mapping] The existance of output elements can be
  efficiently determined from the input.
\item[Collective Work Overlap] In the cases where work is not independent,
  the overlap of responsibility can be resolved through efficient
  collective operations.
\end{description}


\section{Classification of Visualization Algorithms}
\label{sec:Classification}


\algorithmclass{Basic Mapping}
               {Field element (single)} % Input
               {Field element (single)} % Output
               {None} % Overlap
               {Append Attributes, Append Datasets/Geometry, Calculator,
                 Elevation, Generate Ids, Process Ids, Reflect, Transform,
                 Warp}

\noindent
Some of these operate on the coordinates of mesh points, but when treated
as a field the behavior characteristics are the same.


\algorithmclass{Map by Cell}
               {Cell topology (single)} % Input
               {Field element (single)} % Output
               {None} % Overlap
               {Cell Centers, Point Data to Cell Data, Cell Derivitives,
                 Mesh Quality}

\noindent
And now here is some description of this class.


\algorithmclass{Reconnect Cell}
               {Cell topology (single)} % Input
               {Cell connections (zero or more)} % Output
               {None} % Overlap
               {Extract Cells by Region, Extract Selection, Threshold,
                 Triangulate}

\noindent
Description.

Some would benefit from subsetting points. Ours explicitly does this, EAVL
uses selection maps to point back to original data.


\algorithmclass{Build Independent Topology}
               {Cell topology (single)} % Input
               {Cell topology (known constant number)} % Output
               {None} % Overlap
               {Glyph, Shrink, Tube}

\noindent
Description.


\algorithmclass{Build Connected Topology}
               {Cell topology (single)} % Input
               {Cell topology (zero or more)} % Output
               {Duplicate constituent elements of output} % Overlap
               {Clean, Clip, Contour, Extrusion, Isovolume, Slice, Subdivision}

\noindent
Description.


\algorithmclass{Capture Cell Adjacencies}
               {Constituent element (single) with incident cells (varies)} % Input
               {Field or cell connections for constituent element (single)} % Output
               {Duplicate constituent elements of input} % Overlap
               {Curvature, Cell Data to Point Data, Extract Edges, Extract
                 Surface (external faces), Feature Edges, Gradient
                 Estimation, Normal Generation}

\noindent
Description.


\algorithmclass{Globally Reduce}
               {Varies} % Input
               {Aggregated value (single)} % Output
               {Global reduction on intermediate values} % Overlap
               {Histogram, Integrate, Outline, Statistics}

\noindent
Description.


\algorithmclass{Probe Data}
               {Searchable structure, Point location (single)} % Input
               {Varies} % Output
               {None} % Overlap
               {Probe Location, Quadric Clustring, Resample with Dataset,
                 Streamlines, Streaklines}

\noindent
Description.



\algorithmclasssection{Remaining Algorithms}

Extract Subset (from structured data)

Image based algorithms: kernel convolutions (gradient) and FFT.

D3

Connectivity
Delaunay


\bibliographystyle{abbrv}
\bibliography{MassivelyThreadedVis}

\end{document}
